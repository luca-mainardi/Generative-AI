{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJ_pmgxvGur9"
      },
      "source": [
        "# Assignment 1 - Autoregressive models with Transformers\n",
        "## Generative AI Models 2024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEneMITS2agU"
      },
      "source": [
        "#### Instructions on how to use this notebook:\n",
        "\n",
        "This notebook is hosted on ``Google Colab``. To be able to work on it, you have to create your own copy. Go to *File* and select *Save a copy in Drive*.\n",
        "\n",
        "You can also avoid using ``Colab`` entirely, and download the notebook to run it on your own machine. If you choose this, go to *File* and select *Download .ipynb*.\n",
        "\n",
        "The advantage of using **Colab** is that you can use a GPU. You can complete this assignment with a CPU, but it will take a bit longer. Furthermore, we encourage you to train using the GPU not only for faster training, but also to get experience with this setting. This includes moving models and tensors to the GPU and back. This experience is very valuable because for various models and large datasets (like large CNNs for ImageNet, or Transformer models trained on Wikipedia), training on GPU is the only feasible way.\n",
        "\n",
        "The default ``Colab`` runtime does not have a GPU. To change this, go to *Runtime - Change runtime type*, and select *GPU* as the hardware accelerator. The GPU that you get changes according to what resources are available at the time, and its memory can go from a 5GB, to around 18GB if you are lucky. If you are curious, you can run the following in a code cell to check:\n",
        "\n",
        "```sh\n",
        "!nvidia-smi\n",
        "```\n",
        "\n",
        "Note that despite the name, ``Google Colab`` does  not support collaborative work without issues. When two or more people edit the notebook concurrently, only one version will be saved. You can choose to do group programming with one person sharing the screen with the others, or make multiple copies of the notebook to work concurrently.\n",
        "\n",
        "**Submission:** Please bring your (partial) solution to instruction sessions. Then you can discuss it with intructors and your colleagues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBgoJIpdLI2Y",
        "outputId": "d9e4beef-1228-4075-9ea8-7b8b150e92b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsdc7fDp40rQ"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "In this assignment, we are going to implement an autoregressive model (ARM). An AMR is a likelihood-based deep generative model that utilizes the product rule and generates new object one-by-one. Transformers are current state-of-the-art architectures used for Large Language Models (LLMs). Specifically, generative LLMs are parameterized by so called decoder-transformers. The model used in this assignment is based on the architecture of so called Generative Pretrained Transformers (GPTs):\n",
        "- [Radford, A., Narasimhan, K., Salimans, T. and Sutskever, I., 2018. Improving language understanding by generative pre-training.](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)\n",
        "\n",
        "You can read more about ARMs in Chapter 2 of the following book:\n",
        "- [Tomczak, J.M., \"Deep Generative Modeling\", Springer, 2022](https://link.springer.com/book/10.1007/978-3-030-93158-2)\n",
        "\n",
        "You can read more about transformers in Chapter 12 of the following book:\n",
        "- [Prince, S.J.D., \"Understanding Deep Learning\", MIT Press, 2023](https://udlbook.github.io/udlbook/)\n",
        "\n",
        "In particular, the goals of this assignment are the following:\n",
        "\n",
        "- Understand how transformer-based ARMs are formulated.\n",
        "- Implement components of transformer-based ARMs using PyTorch.\n",
        "- Train and evaluate a transformer-based ARM for text data.\n",
        "\n",
        "This notebook is essential for preparing a report. Moreover, please remember to submit the final notebook together with the report (PDF)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvsuVNczG6pP"
      },
      "source": [
        "### Theory behind ARMs\n",
        "\n",
        "Let us consider a high-dimensional random variable $\\mathbf{x} \\in \\mathcal{X}^{T}$ where $\\mathcal{X} = \\{0,1,\\dots , L-1\\}$ or $\\mathcal{X} = \\mathbb{R}$. Our goal is to model $p(\\mathbf{x})$. We can apply the product rule to express this distribution as follows:\n",
        "$$\n",
        "p(\\mathbf{x}) = p(x_1) \\prod_{t=2}^{T} p(x_{t}|\\mathbf{x}_{<t}) ,\n",
        "$$\n",
        "where $\\mathbf{x}_{<t} = [x_1, x_2, \\ldots , x_{t-1}]^{\\top}$. For instance, for $\\mathbf{x} = [x_1, x_2, x_{3}]^{\\top}$, we have $p(\\mathbf{x}) = p(x_1) p(x_{2}|x_{1}) p(x_{3} | x_{1}, x_{2})$.\n",
        "\n",
        "The generative procedure is straightforward: We start with $x_1 \\sim p(x_1)$, and then we proceed with $x_t \\sim p(x_{t}|\\mathbf{x}_{<t})$ by plugging in all previously sampled variables $\\mathbf{x}_{<t}$. We can think of this procedure as a for-loop.\n",
        "\n",
        "Now, the main goal is how to parameterize conditional distributions $p(x_{t}|\\mathbf{x}_{<t})$. We can accomplish that by using neural networks, in particular, transformers. In this assignment, we focus on <i>decoder transformers</i> that utilize causal multi-head self-attention."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIaNyIwxSfN_"
      },
      "source": [
        "### Note\n",
        "\n",
        "In this assignment, we build a simple LLM model. For this purpose, we use a dataset consisting of $\\sim 8.5$k newspaper headlines, and each headline contain at most 150 letters (tokens). You are provided with a tokenizer for turning characters into a sequence of integers and padding, and text processing functions (e.g., removing special characters). Your model will be trained with 1.3M tokens per iteration, and will consist of few millions to over dozen millions of weights.\n",
        "\n",
        "These numbers do not necessarilly impress anyone in the LLM community. However, please be aware that such datasets and models are not small and could be treated as a small-sized LLM-based problems. As you will notice in the end, we can still observe similar phenomena like hallucinations and the power of scaling up."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suzhlbWqxtD9"
      },
      "source": [
        "## IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjxkigYLxpB7",
        "outputId": "96c4db43-45b0-4d97-8910-a1c2d7d15825"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.19.1 dill-0.3.8 multiprocess-0.70.16 xxhash-3.4.1\n",
            "Collecting pytorch_model_summary\n",
            "  Downloading pytorch_model_summary-0.1.2-py3-none-any.whl (9.3 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch_model_summary) (4.66.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pytorch_model_summary) (2.3.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch_model_summary) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_model_summary) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_model_summary) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_model_summary) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_model_summary) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_model_summary) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_model_summary) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->pytorch_model_summary)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->pytorch_model_summary)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->pytorch_model_summary)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->pytorch_model_summary)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->pytorch_model_summary)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->pytorch_model_summary)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->pytorch_model_summary)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->pytorch_model_summary)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->pytorch_model_summary)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->pytorch_model_summary)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->pytorch_model_summary)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_model_summary) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->pytorch_model_summary)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->pytorch_model_summary) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->pytorch_model_summary) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, pytorch_model_summary\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 pytorch_model_summary-0.1.2\n"
          ]
        }
      ],
      "source": [
        "# DO NOT REMOVE!\n",
        "import os\n",
        "\n",
        "import pickle\n",
        "\n",
        "import spacy\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "!pip install datasets\n",
        "from datasets import load_dataset\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "!pip install pytorch_model_summary\n",
        "from pytorch_model_summary import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cm23hRm6CqGh",
        "outputId": "bf9b2f37-7fc1-4402-bc55-bed1f33731cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The available device is cpu\n"
          ]
        }
      ],
      "source": [
        "# DO NOT REMOVE OR MODIFY\n",
        "# Check if GPU is available and determine the device\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    device = 'cpu'\n",
        "\n",
        "print(f'The available device is {device}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81CxONpmMulC",
        "outputId": "43e19fe3-2687-4d44-db8b-518605277a06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# DO NOT REMOVE! (unless you work locally)\n",
        "# mount drive: WE NEED IT FOR SAVING IMAGES! NECESSARY FOR GOOGLE COLAB!\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OoPb92zNM4UY"
      },
      "outputs": [],
      "source": [
        "# DO NOT REMOVE! (unless you work locally)\n",
        "# PLEASE CHANGE IT TO YOUR OWN GOOGLE DRIVE OR YOUR LOCAL DIR!\n",
        "results_model_dir = '/content/drive/My Drive/Results/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3zs31tOyCmq"
      },
      "source": [
        "## Auxiliary classes and functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF0agzL7tDHK"
      },
      "source": [
        "Let us define some useful classes:\n",
        "1. DataProcessor: \"cleaning\" texts.\n",
        "2. Tokenizer: transforming characters to integers and padding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIBNVRNJtHSd"
      },
      "outputs": [],
      "source": [
        "# DO NOT REMOVE OR MODIFY\n",
        "class DataProcessor(object):\n",
        "    def __init__(self, ):\n",
        "        super().__init__()\n",
        "        nlp = spacy.load(\"en_core_web_sm\")\n",
        "        nltk.download('omw-1.4')\n",
        "        nltk.download(\"punkt\")\n",
        "        nltk.download(\"wordnet\")\n",
        "        nltk.download(\"stopwords\")\n",
        "\n",
        "    @staticmethod\n",
        "    def preprocess_text(text):\n",
        "        # Tokenize, remove punctuation and lowercase\n",
        "        tokens = nltk.word_tokenize(text)\n",
        "        tokens = [word.lower() for word in tokens if word.isalpha()]\n",
        "\n",
        "        # Remove stopwords and lemmatize\n",
        "        stop_words = set(stopwords.words(\"english\"))\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        processed_text = [\n",
        "            lemmatizer.lemmatize(word) for word in tokens if word not in stop_words\n",
        "        ]\n",
        "\n",
        "        return \" \".join(processed_text)\n",
        "\n",
        "    def process_batch(self, texts):\n",
        "        return [self.preprocess_text(d) for d in texts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NjoCwjV3TN7"
      },
      "outputs": [],
      "source": [
        "# DO NOT REMOVE OR MODIFY\n",
        "class Tokenizer(object):\n",
        "    def __init__(self, max_length=0):\n",
        "        super().__init__()\n",
        "\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.alphabet_letters = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
        "\n",
        "        self.alphabet = self.prepare_alphabet()\n",
        "        self.decoded_alphabet = self.prepare_decoded_alphabet()\n",
        "\n",
        "    def prepare_alphabet(self):\n",
        "        # PREPARE THE ALPHABET (CHAR->INT)\n",
        "        # as a dictionary\n",
        "        alphabet = {}\n",
        "        alphabet['pad'] = 0  # add 'pad'\n",
        "        count = 1\n",
        "\n",
        "        for letter in self.alphabet_letters:\n",
        "            alphabet[letter] = count\n",
        "            count += 1\n",
        "\n",
        "        # add ' ', 'cls' tokens\n",
        "        alphabet[' '] = count\n",
        "        alphabet['cls'] = count + 1\n",
        "\n",
        "        return alphabet\n",
        "\n",
        "    def prepare_decoded_alphabet(self):\n",
        "        # PREPARE DECODED ALPHABET (INT->CHAR)\n",
        "        decoded_alphabet_ints = [i for i in range(len(self.alphabet_letters))]\n",
        "\n",
        "        decoded_alphabet = {}\n",
        "        decoded_alphabet[0] = 'pad'\n",
        "\n",
        "        for i in decoded_alphabet_ints:\n",
        "            decoded_alphabet[i+1] = self.alphabet_letters[i]\n",
        "\n",
        "            decoded_alphabet[i+2] = ' '\n",
        "        decoded_alphabet[i+3] = 'cls'\n",
        "\n",
        "        return decoded_alphabet\n",
        "\n",
        "    def encode(self, texts):\n",
        "        N = len(texts)\n",
        "\n",
        "        if self.max_length == 0:\n",
        "            max_length = 0\n",
        "            for i in range(N):\n",
        "                len_i = len(texts[i])\n",
        "                if len_i > max_length:\n",
        "                    max_length = len_i\n",
        "        else:\n",
        "            max_length = self.max_length\n",
        "\n",
        "        tokens = np.zeros((N, max_length+1))\n",
        "\n",
        "        for i in range(N):\n",
        "            len_i = len(texts[i])\n",
        "            for j in range(-1, max_length):\n",
        "                if j == -1:\n",
        "                    tokens[i,j+1] = self.alphabet['cls']\n",
        "                elif j >= len_i:\n",
        "                    tokens[i,j+1] = self.alphabet['pad']\n",
        "                else:\n",
        "                    if texts[i][j] == 'é':\n",
        "                        tokens[i,j+1] = self.alphabet['e']\n",
        "                    elif texts[i][j] == 'í':\n",
        "                        tokens[i,j+1] = self.alphabet['e']\n",
        "                    elif texts[i][j] == 'á':\n",
        "                        tokens[i,j+1] = self.alphabet['a']\n",
        "                    elif texts[i][j] == 'ó':\n",
        "                        tokens[i,j+1] = self.alphabet['o']\n",
        "                    elif texts[i][j] == 'æ':\n",
        "                        tokens[i,j+1] = self.alphabet['a']\n",
        "                    elif texts[i][j] == 'ä':\n",
        "                        tokens[i,j+1] = self.alphabet['a']\n",
        "                    else:\n",
        "                        tokens[i,j+1] = self.alphabet[texts[i][j]]\n",
        "\n",
        "        return tokens\n",
        "\n",
        "    def decode(self, tokens):\n",
        "        texts = []\n",
        "\n",
        "        for i in range(len(tokens)):\n",
        "            tokens_i = tokens[i,:]\n",
        "            text_i = ''\n",
        "            for j in range(len(tokens_i)):\n",
        "                if tokens_i[j] == 0:\n",
        "                    break\n",
        "                else:\n",
        "                    if self.decoded_alphabet[tokens_i[j]] != 'cls':\n",
        "                        text_i += self.decoded_alphabet[tokens_i[j]]\n",
        "            texts.append(text_i)\n",
        "\n",
        "        return texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhiWi-j3mELC"
      },
      "source": [
        "Some useful functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MoB-RuczmGlT"
      },
      "outputs": [],
      "source": [
        "# DO NOT REMOVE OR MODIFY\n",
        "def save_texts(sampled_texts, name=''):\n",
        "    # open file in write mode\n",
        "    with open(results_dir + '/samples_' + name + '.txt', 'w') as fp:\n",
        "        for item in sampled_texts:\n",
        "            # write each item in a new line\n",
        "            fp.write(\"%s\\n\" % item)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q60onqQR3TN8"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0K9XaWO_3TN8"
      },
      "outputs": [],
      "source": [
        "# DO NOT REMOVE OR MODIFY\n",
        "class Headers(Dataset):\n",
        "    \"\"\"A simple dataset based on headers. Source: https://huggingface.co/datasets/IlyaGusev/headline_cause\"\"\"\n",
        "\n",
        "    def __init__(self, dataprocessor, tokenizer, mode='train', num_training_data=None, transforms=None):\n",
        "        # LOAD DATA\n",
        "        dataset = load_dataset(\"IlyaGusev/headline_cause\", \"en_simple\")\n",
        "\n",
        "        # PREPARE DATA\n",
        "        if mode == 'train':\n",
        "            train_texts = dataprocessor.process_batch(dataset['train'][:]['left_title'] + dataset['train'][:]['right_title']) # list\n",
        "            if num_training_data is None:\n",
        "                self.data = torch.from_numpy(tokenizer.encode(train_texts)).long()\n",
        "            else:\n",
        "                self.data = torch.from_numpy(tokenizer.encode(train_texts))[:num_training_data].long()\n",
        "        elif mode == 'val':\n",
        "            validation_texts = dataprocessor.process_batch(dataset['validation'][:]['left_title'] + dataset['validation'][:]['right_title']) # list\n",
        "            self.data = torch.from_numpy(tokenizer.encode(validation_texts)).long()\n",
        "        else:\n",
        "            test_texts = dataprocessor.process_batch(dataset['test'][:]['left_title'] + dataset['test'][:]['right_title']) # list\n",
        "            self.data = torch.from_numpy(tokenizer.encode(test_texts)).long()\n",
        "\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.data[idx]\n",
        "        if self.transforms:\n",
        "            sample = self.transforms(sample)\n",
        "        return sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2LLOs0kn7iw"
      },
      "source": [
        "## Implementing ARMs with Transformers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cXhOwKAzW6Z"
      },
      "source": [
        "### Loss Function (NLL)\n",
        "Our loss function is the negative log-likelihood for the categorical distribution (i.e., the cross-entropy loss).\n",
        "\n",
        "Please note how it is implemented and how tokens (T) are handled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrwQXSuEoFfH"
      },
      "outputs": [],
      "source": [
        "# DO NOT REMOVE OR MODIFY\n",
        "class LossFun(nn.Module):\n",
        "    def __init__(self,):\n",
        "        super().__init__()\n",
        "\n",
        "        self.loss = nn.NLLLoss(reduction='none')\n",
        "\n",
        "    def forward(self, y_model, y_true, reduction='sum'):\n",
        "        # y_model: B(atch) x T(okens) x V(alues)\n",
        "        # y_true: B x T\n",
        "        B, T, V = y_model.size()\n",
        "\n",
        "        y_model = y_model.view(B * T, V)\n",
        "        y_true = y_true.view(B * T,)\n",
        "\n",
        "        loss_matrix = self.loss(y_model, y_true) # B*T\n",
        "\n",
        "        if reduction == 'sum':\n",
        "            return torch.sum(loss_matrix)\n",
        "        elif reduction == 'mean':\n",
        "            loss_matrix = loss_matrix.view(B, T)\n",
        "            return torch.mean(torch.sum(loss_matrix, 1))\n",
        "        else:\n",
        "            raise ValueError('Reduction could be either `sum` or `mean`.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhNTy5mn0XDT"
      },
      "source": [
        "### Transformer block\n",
        "\n",
        "Transformers consist of transformer block. In the cell below, please define a transformer block."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadSelfAttention(nn.Module):\n",
        "    def __init__(self, num_emb, num_heads=8):\n",
        "        super().__init__()\n",
        "\n",
        "        # hyperparams\n",
        "        self.D = num_emb\n",
        "        self.H = num_heads\n",
        "\n",
        "        # weights for self-attention\n",
        "        self.w_k = nn.Linear(self.D, self.D * self.H)\n",
        "        self.w_q = nn.Linear(self.D, self.D * self.H)\n",
        "        self.w_v = nn.Linear(self.D, self.D * self.H)\n",
        "\n",
        "        # weights for a combination of multiple heads\n",
        "        self.w_c = nn.Linear(self.D * self.H, self.D)\n",
        "\n",
        "    def forward(self, x, causal=True):\n",
        "        # x: B(atch) x T(okens) x D(imensionality)\n",
        "        B, T, D = x.size()\n",
        "\n",
        "        # keys, queries, values\n",
        "        k = self.w_k(x).view(B, T, self.H, D) # B x T x H x D\n",
        "        q = self.w_q(x).view(B, T, self.H, D) # B x T x H x D\n",
        "        v = self.w_v(x).view(B, T, self.H, D) # B x T x H x D\n",
        "\n",
        "        k = k.transpose(1, 2).contiguous().view(B * self.H, T, D) # B*H x T x D\n",
        "        q = q.transpose(1, 2).contiguous().view(B * self.H, T, D) # B*H x T x D\n",
        "        v = v.transpose(1, 2).contiguous().view(B * self.H, T, D) # B*H x T x D\n",
        "\n",
        "        k = k / (D**0.25) # scaling\n",
        "        q = q / (D**0.25) # scaling\n",
        "\n",
        "        # kq\n",
        "        kq = torch.bmm(q, k.transpose(1, 2)) # B*H x T x T\n",
        "\n",
        "        # if causal\n",
        "        if causal:\n",
        "            mask = torch.triu_indices(T, T, offset=1)\n",
        "            kq[..., mask[0], mask[1]] = float('-inf')\n",
        "\n",
        "        # softmax\n",
        "        skq = F.softmax(kq, dim=2)\n",
        "\n",
        "        # self-attention\n",
        "        sa = torch.bmm(skq, v) # B*H x T x D\n",
        "        sa = sa.view(B, self.H, T, D) # B x H x T x D\n",
        "        sa = sa.transpose(1, 2) # B x T x H x D\n",
        "        sa = sa.contiguous().view(B, T, D * self.H) # B x T x D*H\n",
        "\n",
        "        out = self.w_c(sa) # B x T x D\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "B33b7qqOLTpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vTmKHwrpUVa"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE GOES HERE\n",
        "# NOTE: The class must containt the following elements:\n",
        "# (i) components (nn.Module) of a transformer bloc\n",
        "# (ii) the forward function\n",
        "# Moreover, forward must return the processed input\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, num_emb, num_neurons, num_heads=4):\n",
        "        super().__init__()\n",
        "\n",
        "        # hyperparams\n",
        "        self.D = num_emb\n",
        "        self.H = num_heads\n",
        "        self.neurons = num_neurons\n",
        "\n",
        "        # components\n",
        "        self.msha = MultiHeadSelfAttention(num_emb=self.D, num_heads=self.H)\n",
        "        self.layer_norm1 = nn.LayerNorm(self.D)\n",
        "        self.layer_norm2 = nn.LayerNorm(self.D)\n",
        "\n",
        "        self.mlp = nn.Sequential(nn.Linear(self.D, self.neurons * self.D),\n",
        "                                nn.GELU(),\n",
        "                                nn.Linear(self.neurons * self.D, self.D))\n",
        "\n",
        "    def forward(self, x, causal=True):\n",
        "        # Multi-Head Self-Attention\n",
        "        x_attn = self.msha(x, causal)\n",
        "        # LayerNorm\n",
        "        x = self.layer_norm1(x_attn + x)\n",
        "        # MLP\n",
        "        x_mlp = self.mlp(x)\n",
        "        # LayerNorm\n",
        "        x = self.layer_norm2(x_mlp + x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLIEwIiw00op"
      },
      "source": [
        "### ARM (Decoder-Transformer)\n",
        "\n",
        "Once we have a class for transformer blocks, we need to define a decoder-transformer that defines an auto-regressive model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQIvee5Cp69V"
      },
      "outputs": [],
      "source": [
        "# DO NOT REMOVE OR MODIFY\n",
        "class DecoderTransformer(nn.Module):\n",
        "    def __init__(self, num_tokens, num_token_vals, num_emb, num_neurons, num_heads=2, dropout_prob=0.1, num_blocks=10, device='cpu'):\n",
        "        super().__init__()\n",
        "\n",
        "        # hyperparams\n",
        "        self.device = device\n",
        "        self.num_tokens = num_tokens\n",
        "        self.num_token_vals = num_token_vals\n",
        "        self.num_emb = num_emb\n",
        "        self.num_blocks = num_blocks\n",
        "\n",
        "        # embedding layer\n",
        "        self.embedding = torch.nn.Embedding(num_token_vals, num_emb)\n",
        "\n",
        "        # positional embedding\n",
        "        self.positional_embedding = nn.Embedding(num_tokens, num_emb)\n",
        "\n",
        "        # transformer blocks\n",
        "        self.transformer_blocks = nn.ModuleList()\n",
        "        for _ in range(num_blocks):\n",
        "            self.transformer_blocks.append(TransformerBlock(num_emb=num_emb, num_neurons=num_neurons, num_heads=num_heads))\n",
        "\n",
        "        # output layer (logits + softmax)\n",
        "        self.logits = nn.Sequential(nn.Linear(num_emb, num_token_vals))\n",
        "\n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "\n",
        "        # loss function\n",
        "        self.loss_fun = LossFun()\n",
        "\n",
        "    def transformer_forward(self, x, causal=True, temperature=1.0):\n",
        "        # x: B(atch) x T(okens)\n",
        "        # embedding of tokens\n",
        "        x = self.embedding(x) # B x T x D\n",
        "        # embedding of positions\n",
        "        pos = torch.arange(0, x.shape[1], dtype=torch.long).unsqueeze(0).to(self.device)\n",
        "        pos_emb = self.positional_embedding(pos)\n",
        "        # dropout of embedding of inputs\n",
        "        x = self.dropout(x + pos_emb)\n",
        "\n",
        "        # transformer blocks\n",
        "        for i in range(self.num_blocks):\n",
        "            x = self.transformer_blocks[i](x)\n",
        "\n",
        "        # output logits\n",
        "        out = self.logits(x)\n",
        "\n",
        "        return F.log_softmax(out/temperature, 2)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def sample(self, batch_size=4, temperature=1.0):\n",
        "        x_seq = np.asarray([[self.num_token_vals - 1] for i in range(batch_size)])\n",
        "\n",
        "        # sample next tokens\n",
        "        for i in range(self.num_tokens-1):\n",
        "            xx = torch.tensor(x_seq, dtype=torch.long, device=self.device)\n",
        "            # process x and calculate log_softmax\n",
        "            x_log_probs = self.transformer_forward(xx, temperature=temperature)\n",
        "            # sample i-th tokens\n",
        "            x_i_sample = torch.multinomial(torch.exp(x_log_probs[:,i]), 1).to(self.device)\n",
        "            # update the batch with new samples\n",
        "            x_seq = np.concatenate((x_seq, x_i_sample.to('cpu').detach().numpy()), 1)\n",
        "\n",
        "        return x_seq\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def top1_rec(self, x, causal=True):\n",
        "        x_prob = torch.exp(self.transformer_forward(x, causal=True))[:,:-1,:].contiguous()\n",
        "        _, x_rec_max = torch.max(x_prob, dim=2)\n",
        "        return torch.sum(torch.mean((x_rec_max.float() == x[:,1:].float().to(device)).float(), 1).float())\n",
        "\n",
        "    def forward(self, x, causal=True, temperature=1.0, reduction='mean'):\n",
        "        # get log-probabilities\n",
        "        log_prob = self.transformer_forward(x, causal=causal, temperature=temperature)\n",
        "\n",
        "        return self.loss_fun(log_prob[:,:-1].contiguous(), x[:,1:].contiguous(), reduction=reduction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLhgze7DA4yx"
      },
      "source": [
        "### Evaluation and training functions\n",
        "\n",
        "**Please DO NOT remove or modify them.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9Dr3a6lqJ0W"
      },
      "outputs": [],
      "source": [
        "# DO NOT REMOVE OR MODIFY\n",
        "def evaluation(test_loader, name=None, model_best=None, epoch=None, device='cuda'):\n",
        "    # EVALUATION\n",
        "    if model_best is None:\n",
        "        # load best performing model\n",
        "        model_best = torch.load(name + '.model').to(device)\n",
        "\n",
        "    model_best.eval()\n",
        "    loss = 0.\n",
        "    rec = 1.\n",
        "    N = 0.\n",
        "    for indx_batch, test_batch in enumerate(test_loader):\n",
        "        loss_t = model_best.forward(test_batch.to(device), reduction='sum')\n",
        "        loss = loss + loss_t.item()\n",
        "\n",
        "        rec_t = model_best.top1_rec(test_batch.to(device))\n",
        "        rec = rec + rec_t.item()\n",
        "\n",
        "        N = N + test_batch.shape[0]\n",
        "    loss = loss / N\n",
        "    rec = rec / N\n",
        "\n",
        "    if epoch is None:\n",
        "        print(f'FINAL LOSS: nll={loss}, rec={rec}')\n",
        "    else:\n",
        "        print(f'Epoch: {epoch}, val nll={loss}, val rec={rec}')\n",
        "\n",
        "    return loss, rec\n",
        "\n",
        "def plot_curve(name, nll_val, ylabel='nll'):\n",
        "    plt.plot(np.arange(len(nll_val)), nll_val, linewidth='3')\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.savefig(name + '_' + ylabel + '_val_curve.pdf', bbox_inches='tight')\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ABgMeG0qFAP"
      },
      "outputs": [],
      "source": [
        "# DO NOT REMOVE OR MODIFY\n",
        "def training(name, max_patience, num_epochs, model, optimizer, training_loader, val_loader, device='cuda'):\n",
        "    nll_val = []\n",
        "    rec_val = []\n",
        "    best_nll = 1000.\n",
        "    patience = 0\n",
        "\n",
        "    # Main loop\n",
        "    for e in range(num_epochs):\n",
        "        # TRAINING\n",
        "        model.train()\n",
        "        for indx_batch, batch in enumerate(training_loader):\n",
        "            loss = model.forward(batch.to(device))\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward(retain_graph=True)\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validation\n",
        "        loss_val, r_val = evaluation(val_loader, model_best=model, epoch=e, device=device)\n",
        "        nll_val.append(loss_val)  # save for plotting\n",
        "        rec_val.append(r_val)\n",
        "\n",
        "        if e == 0:\n",
        "            print('saved!')\n",
        "            torch.save(model, name + '.model')\n",
        "            best_nll = loss_val\n",
        "\n",
        "            sampled_tokens = model.sample(batch_size=64, temperature=1.0)\n",
        "            sampled_texts = tokenizer.decode(sampled_tokens)\n",
        "            save_texts(sampled_texts, name='epoch_' + str(e))\n",
        "\n",
        "        else:\n",
        "            if loss_val < best_nll:\n",
        "                print('saved!')\n",
        "                torch.save(model, name + '.model')\n",
        "                best_nll = loss_val\n",
        "                patience = 0\n",
        "\n",
        "                sampled_tokens = model.sample(batch_size=64, temperature=1.0)\n",
        "                sampled_texts = tokenizer.decode(sampled_tokens)\n",
        "                save_texts(sampled_texts, name='epoch_' + str(e))\n",
        "            else:\n",
        "                patience = patience + 1\n",
        "\n",
        "        if patience > max_patience:\n",
        "            break\n",
        "\n",
        "    nll_val = np.asarray(nll_val)\n",
        "    rec_val = np.asarray(rec_val)\n",
        "\n",
        "    np.save(name + '_nll_val.npy', nll_val)\n",
        "    np.save(name + '_rec_val.npy', rec_val)\n",
        "\n",
        "    return nll_val, rec_val"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWr8N2u2qNTu"
      },
      "source": [
        "### Setup\n",
        "\n",
        "**NOTE: *Please comment your code! Especially if you introduce any new variables (e.g., hyperparameters).***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFTE5jtYpxDV",
        "outputId": "1fbb99c7-6c90-40e7-f6d7-b64c6ca1ca35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "# DO NOT REMOVE OR MODIFY\n",
        "dataprocessor = DataProcessor()\n",
        "tokenizer = Tokenizer(max_length=149)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXHitzrYqNhY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333,
          "referenced_widgets": [
            "35a467530d66453689e2a0113109f774",
            "ce9b81ec6f944b7387b9c06330bc75fe",
            "66f8d6eff444476ab8f67392746021fd",
            "3fb34f18e4bd44c8bd1a5f3df45cb02b",
            "484775bf86f549f9a0f72fe6e9c0a59f",
            "1ce89fbe5fa846bd9e6585d47ff47799",
            "30481408fb7947208009c49077d006ff",
            "f49197a76ac64b5cbec02632b21818f9",
            "1ec0a29b00504684a9a77c8675edcd0b",
            "94b884fdc3ea4535848bc71b01890545",
            "46ec987408f3427aad71a1f1c9fb7d48",
            "937c88cbc55647c0a6aaded271fc111c",
            "4e496431a95144efa1c8b48ee5df1f06",
            "a7c2b4812d88444d869d43c1f28e3fa3",
            "d68b00809f824d45bbd56ff8a6f575c7",
            "70d458b2f7e94a6ba7f3f148c6d5b599",
            "6413b232982d41a2bd438256a63ce097",
            "ee55f368c2ed4cd4af1824cc0566d7f6",
            "f765e7fcbc2042e0afba9201f167c000",
            "a853f46f412643bca98045b23f72319e",
            "aa7dca7dd761463eb51328506a239d56",
            "33fe0e4fe4564a9d86ee4fae8585011a",
            "820119839ddc4b73a69aa5ee131ba22f",
            "2684bf5601154780a411081e6b79ad70",
            "e1482300b86c46dea53aea5cd9d6596e",
            "fcc4cf07f4724b4f885a4e93717c19e1",
            "fc4beaf3552b416e95b68222a48edd6e",
            "f3d63e3eab564014a058ef067a1d363a",
            "a601020ef32e42ce907b9387bdf260c6",
            "c28477916114428aa951e747153ee13d",
            "e0ee5d6a512c492b856874eee4ee61fc",
            "f5561ac636c14b6d8852dfb0fc3b3d58",
            "bcd3a12afd2942359c41cf3105de327b",
            "9f05bbf93ff74af190ddc641c5949fc4",
            "86b315fb87da4d65a62634fa1e249309",
            "f2a8e8fefcf344369ea9f32e5fb9b224",
            "4006b1b90e7f4c1b8235f32a8462a4ac",
            "8947aa44eb0b425c9f396f108aecfbf9",
            "a60afda4868140fdb60b3461c7580c95",
            "1f481007ad43439ba66a400b66c70ee8",
            "db860757ea2a4c2f84c8ff6b419dacba",
            "f1cf756c2a1d4d2a9cfffe2f340a108a",
            "3842daadc5c848afbc4b70da45752679",
            "6233591379524fe6be018304e7dae044",
            "e012b07b3128486bb9e6771b9c235ec1",
            "fecbd7889b914931b9751e15b7d2b720",
            "5a8e1e738a2045f69004eb9e95e57ec7",
            "a15cd8e9bf9345a5805c245e4c628ec9",
            "73c4baf1a6604bcca121f7fff447df6f",
            "29fbd1094b714b87ae5bbbf4aad98baa",
            "08fc3a4bb2944b319042e09de4de22c5",
            "fd0be328924945858a55c1e8c3758887",
            "e57868a2b05a4873adf4fe126c5400f4",
            "4e9e56cee3ea47ce9a27c5c6e1a4a23a",
            "517ee8860c09433f9da28af92f2acfc6",
            "1df2ccf9bf3e4399b8e081497a1520c8",
            "1ecf4cf0984045e8bae39d7279dd1670",
            "ce661f686b904c0381b5f6432ea9880b",
            "4201f46209c24701aabe4be7ff490044",
            "15746ca77fbd40e5a12b09192d96bd91",
            "87e8fccc5a6b48878169f15c6fdbc9f9",
            "45f92e3492f24b278b3d233f8c09a4b3",
            "aaa5cc1343c6464c89b7eee18c4720af",
            "a3ea1ee14cbf4fd5abac431dcad78d6f",
            "9add18beb9df4e269c623cc5c20df508",
            "68ccc11c2c4b47248e26d85c37150de6"
          ]
        },
        "outputId": "848a7ade-1e69-4956-bfd8-272ab9948466"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/1.13M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35a467530d66453689e2a0113109f774"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/148k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "937c88cbc55647c0a6aaded271fc111c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/145k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "820119839ddc4b73a69aa5ee131ba22f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/4332 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f05bbf93ff74af190ddc641c5949fc4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/542 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e012b07b3128486bb9e6771b9c235ec1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/542 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1df2ccf9bf3e4399b8e081497a1520c8"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# PLEASE MODIFY ACCORDING TO THE REPORT REQUIREMENTS\n",
        "num_training_data = None  # None to take all training data\n",
        "\n",
        "# DO NOT REMOVE OR MODIFY THE REST OF THIS CELL\n",
        "#-dataset\n",
        "train_dataset = Headers(dataprocessor, tokenizer, num_training_data=num_training_data, mode=\"train\")\n",
        "validation_dataset = Headers(dataprocessor, tokenizer, mode=\"val\")\n",
        "test_dataset = Headers(dataprocessor, tokenizer, mode=\"test\")\n",
        "\n",
        "#-dataloaders\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "training_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a92GEnnsA87"
      },
      "source": [
        "# **1.** Model with $<100$k weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTBFl-bNb0s9"
      },
      "outputs": [],
      "source": [
        "# DO NOT REMOVE (but you can modify if necessary)\n",
        "#-creating a dir for saving results\n",
        "name = 'arm_transformer_1'  # NOTE: if you run multiple experiments, you would overwrite results. Please modify this part if necessary.\n",
        "results_dir = results_model_dir + name + '/'\n",
        "if not(os.path.exists(results_dir)):\n",
        "  os.mkdir(results_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmKDXMI0B231"
      },
      "source": [
        "In the next cell, please initialize the model. Please remember about commenting your code!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b73aaBDxqSYb"
      },
      "outputs": [],
      "source": [
        "# DO NOT REMOVE but PLEASE MODIFY WHENEVER YOU ARE ASKED FOR IT!\n",
        "# NOTE: in order to obtain required sizes of your models, you can play with\n",
        "#       various values of num_neurons, num_heads, num_blocks, num_emb\n",
        "num_tokens = 150 # do not modify!\n",
        "num_token_vals = 29  # do not modify!\n",
        "num_neurons = 10 # please modify it\n",
        "num_heads = 5 # please modify it\n",
        "num_blocks = 5 # please modify it\n",
        "num_emb = num_heads * 4  # please modify it but it must be a multiplication of num_heads\n",
        "causal=True # do not modify!\n",
        "\n",
        "lr = 1e-3 # learning rate; do not modify!\n",
        "num_epochs = 1000 # max. number of epochs; do not modify!\n",
        "max_patience = 10 # an early stopping is used, if training doesn't improve for longer than 20 epochs, it is stopped; do not modify!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQy_iNJs3TOD",
        "outputId": "79f50e66-aa50-405c-8e03-1ef2a6a78b94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------\n",
            "         Layer (type)        Output Shape         Param #     Tr. Param #\n",
            "==========================================================================\n",
            "          Embedding-1        [1, 150, 20]             580             580\n",
            "          Embedding-2        [1, 150, 20]           3,000           3,000\n",
            "            Dropout-3        [1, 150, 20]               0               0\n",
            "   TransformerBlock-4        [1, 150, 20]          16,620          16,620\n",
            "   TransformerBlock-5        [1, 150, 20]          16,620          16,620\n",
            "   TransformerBlock-6        [1, 150, 20]          16,620          16,620\n",
            "   TransformerBlock-7        [1, 150, 20]          16,620          16,620\n",
            "   TransformerBlock-8        [1, 150, 20]          16,620          16,620\n",
            "             Linear-9        [1, 150, 29]             609             609\n",
            "           LossFun-10                  []               0               0\n",
            "==========================================================================\n",
            "Total params: 87,289\n",
            "Trainable params: 87,289\n",
            "Non-trainable params: 0\n",
            "--------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# DO NOT REMOVE OR MODIFY\n",
        "model = DecoderTransformer(num_tokens=num_tokens, num_token_vals=num_token_vals, num_emb=num_emb, num_neurons=num_neurons, num_heads=num_heads, num_blocks=num_blocks, device=device)\n",
        "model = model.to(device)\n",
        "# Print the summary (like in Keras)\n",
        "print(summary(model, torch.zeros(1, num_tokens, dtype=torch.long).to(device), show_input=False, show_hierarchical=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iC8AkWt4CURT"
      },
      "source": [
        "Please initialize the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3nTSDe7ql08"
      },
      "outputs": [],
      "source": [
        "# DO NOT REMOVE OR MODIFY\n",
        "optimizer = torch.optim.AdamW([p for p in model.parameters() if p.requires_grad == True], lr=lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5GrzUcHFweG"
      },
      "source": [
        "## Training and final evaluation\n",
        "\n",
        "In the following two cells, we run the training and the final evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0S3WuG3qpm1x",
        "outputId": "2813bf2a-49fe-4984-e788-5791512a77f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, val nll=150.11425533505823, val rec=0.7034721075388778\n",
            "saved!\n",
            "Epoch: 1, val nll=141.23683194656653, val rec=0.7145979342865328\n",
            "saved!\n",
            "Epoch: 2, val nll=136.89613055127134, val rec=0.721488896331224\n",
            "saved!\n",
            "Epoch: 3, val nll=134.1142120924383, val rec=0.7267701001184893\n",
            "saved!\n",
            "Epoch: 4, val nll=131.06994809083832, val rec=0.7328252282089853\n",
            "saved!\n",
            "Epoch: 5, val nll=127.96223117504613, val rec=0.7388741767714384\n",
            "saved!\n",
            "Epoch: 6, val nll=125.42319322424181, val rec=0.7439820247382696\n",
            "saved!\n",
            "Epoch: 7, val nll=123.44612690267527, val rec=0.7489350959383694\n",
            "saved!\n",
            "Epoch: 8, val nll=121.70628689136012, val rec=0.7520679125486704\n",
            "saved!\n",
            "Epoch: 9, val nll=120.37328133107991, val rec=0.7548849697042656\n",
            "saved!\n",
            "Epoch: 10, val nll=118.73346803109145, val rec=0.7579125284708734\n",
            "saved!\n",
            "Epoch: 11, val nll=117.44606339007726, val rec=0.7613920637602296\n",
            "saved!\n",
            "Epoch: 12, val nll=116.15168655226591, val rec=0.7635156835577145\n",
            "saved!\n",
            "Epoch: 13, val nll=114.76345453579047, val rec=0.7664132417348039\n",
            "saved!\n",
            "Epoch: 14, val nll=114.3435747773005, val rec=0.7682520613019317\n",
            "saved!\n",
            "Epoch: 15, val nll=112.9560855429111, val rec=0.7710877027898697\n",
            "saved!\n",
            "Epoch: 16, val nll=112.18318136855684, val rec=0.7737871184120318\n",
            "saved!\n",
            "Epoch: 17, val nll=111.75407629259398, val rec=0.7746353325368733\n",
            "saved!\n",
            "Epoch: 18, val nll=110.79378585533902, val rec=0.7751244530906537\n",
            "saved!\n",
            "Epoch: 19, val nll=109.9159572925075, val rec=0.7779662758661812\n",
            "saved!\n",
            "Epoch: 20, val nll=109.3145677629872, val rec=0.7786597061861045\n",
            "saved!\n",
            "Epoch: 21, val nll=108.51398042911093, val rec=0.7802818305378031\n",
            "saved!\n",
            "Epoch: 22, val nll=108.22325151168992, val rec=0.7822878193591354\n",
            "saved!\n",
            "Epoch: 23, val nll=107.59959743823512, val rec=0.7834084553032343\n",
            "saved!\n",
            "Epoch: 24, val nll=107.33399766309675, val rec=0.783266060466696\n",
            "saved!\n",
            "Epoch: 25, val nll=106.94694626023409, val rec=0.7833836914428486\n",
            "saved!\n",
            "Epoch: 26, val nll=106.09680536136416, val rec=0.7864546001617319\n",
            "saved!\n",
            "Epoch: 27, val nll=106.06516865522659, val rec=0.7866712918580678\n",
            "saved!\n",
            "Epoch: 28, val nll=105.6499426584842, val rec=0.7875876180360238\n",
            "saved!\n",
            "Epoch: 29, val nll=104.86626228811116, val rec=0.7893397570536146\n",
            "saved!\n",
            "Epoch: 30, val nll=104.91193302619061, val rec=0.7890301964819652\n",
            "Epoch: 31, val nll=104.85872253192747, val rec=0.7895131128740487\n",
            "saved!\n",
            "Epoch: 32, val nll=105.24629847677872, val rec=0.7896555217869607\n",
            "Epoch: 33, val nll=104.02246724371541, val rec=0.7914386217884471\n",
            "saved!\n",
            "Epoch: 34, val nll=103.62879363901061, val rec=0.7910609474041366\n",
            "saved!\n",
            "Epoch: 35, val nll=103.51343178837062, val rec=0.7922496918822567\n",
            "saved!\n",
            "Epoch: 36, val nll=103.23169598456238, val rec=0.7933517505321995\n",
            "saved!\n",
            "Epoch: 37, val nll=103.21947566521564, val rec=0.7933888998418717\n",
            "saved!\n",
            "Epoch: 38, val nll=102.87731325494407, val rec=0.7933331714784967\n",
            "saved!\n",
            "Epoch: 39, val nll=102.55862888462869, val rec=0.7945962040186808\n",
            "saved!\n",
            "Epoch: 40, val nll=102.52313097288688, val rec=0.7946023941040039\n",
            "saved!\n",
            "Epoch: 41, val nll=102.47634403468058, val rec=0.7956549179949883\n",
            "saved!\n",
            "Epoch: 42, val nll=103.20325337652791, val rec=0.7929493017302228\n",
            "Epoch: 43, val nll=102.72943858466905, val rec=0.7940513674183526\n",
            "Epoch: 44, val nll=101.52133775549181, val rec=0.7969427231932918\n",
            "saved!\n",
            "Epoch: 45, val nll=102.09110949752076, val rec=0.795555869591632\n",
            "Epoch: 46, val nll=101.60946666534537, val rec=0.7972213245405922\n",
            "Epoch: 47, val nll=101.14613595659883, val rec=0.7983110047794356\n",
            "saved!\n",
            "Epoch: 48, val nll=101.18906326575473, val rec=0.7978218877447487\n",
            "Epoch: 49, val nll=100.89848186872982, val rec=0.7987072476601689\n",
            "saved!\n",
            "Epoch: 50, val nll=100.63817053087523, val rec=0.7989610921852703\n",
            "saved!\n",
            "Epoch: 51, val nll=100.7042353443554, val rec=0.7995368985672279\n",
            "Epoch: 52, val nll=100.73703419590348, val rec=0.7996111901483852\n",
            "Epoch: 53, val nll=100.45389616005535, val rec=0.7989982467735826\n",
            "saved!\n",
            "Epoch: 54, val nll=100.20412926480338, val rec=0.8003541464295334\n",
            "saved!\n",
            "Epoch: 55, val nll=100.58898295159709, val rec=0.7987877398839296\n",
            "Epoch: 56, val nll=100.21254153093288, val rec=0.7990415896876711\n",
            "Epoch: 57, val nll=100.67859066896332, val rec=0.7999393297737375\n",
            "Epoch: 58, val nll=100.43161877846806, val rec=0.7990601511459069\n",
            "Epoch: 59, val nll=99.90142642088043, val rec=0.8005708434045095\n",
            "saved!\n",
            "Epoch: 60, val nll=100.60321495365832, val rec=0.7997040590236988\n",
            "Epoch: 61, val nll=99.68466738317285, val rec=0.8017348205031504\n",
            "saved!\n",
            "Epoch: 62, val nll=99.95113313681965, val rec=0.8003169936007679\n",
            "Epoch: 63, val nll=99.98332388902503, val rec=0.8006265647296976\n",
            "Epoch: 64, val nll=99.38277984281308, val rec=0.8026944860761016\n",
            "saved!\n",
            "Epoch: 65, val nll=99.23913394041168, val rec=0.8025396846757163\n",
            "saved!\n",
            "Epoch: 66, val nll=99.70272320398985, val rec=0.800775161968386\n",
            "Epoch: 67, val nll=99.23240498335159, val rec=0.8018586433241728\n",
            "saved!\n",
            "Epoch: 68, val nll=99.64183691946782, val rec=0.8011342520203537\n",
            "Epoch: 69, val nll=99.11875662152617, val rec=0.802477767986565\n",
            "saved!\n",
            "Epoch: 70, val nll=98.99298771369061, val rec=0.8020629530903158\n",
            "saved!\n",
            "Epoch: 71, val nll=99.42041466068957, val rec=0.8023291760265168\n",
            "Epoch: 72, val nll=99.0039539970595, val rec=0.8029049736107408\n",
            "Epoch: 73, val nll=99.01970196825992, val rec=0.8022858489483485\n",
            "Epoch: 74, val nll=98.47386591724803, val rec=0.8030473790045594\n",
            "saved!\n",
            "Epoch: 75, val nll=98.70098471553563, val rec=0.803090709601821\n",
            "Epoch: 76, val nll=98.77012808824378, val rec=0.8030473807641061\n",
            "Epoch: 77, val nll=98.59763755657576, val rec=0.8035612669378189\n",
            "Epoch: 78, val nll=98.7629277415821, val rec=0.8029421246799596\n",
            "Epoch: 79, val nll=98.35506740443381, val rec=0.8038027277731807\n",
            "saved!\n",
            "Epoch: 80, val nll=98.49929460476245, val rec=0.8038770158352447\n",
            "Epoch: 81, val nll=98.55269631248558, val rec=0.8031092956937107\n",
            "Epoch: 82, val nll=98.76519054680293, val rec=0.8040008386562671\n",
            "Epoch: 83, val nll=98.12320002594558, val rec=0.8045580624654284\n",
            "saved!\n",
            "Epoch: 84, val nll=98.41430799195687, val rec=0.8042670791879352\n",
            "Epoch: 85, val nll=98.09544502061232, val rec=0.804087526243991\n",
            "saved!\n",
            "Epoch: 86, val nll=98.09953752918877, val rec=0.8043351718860359\n",
            "Epoch: 87, val nll=98.32980920995733, val rec=0.804081336158668\n",
            "Epoch: 88, val nll=98.25900257293588, val rec=0.8040441815703557\n",
            "Epoch: 89, val nll=97.89240965895988, val rec=0.8050348046081093\n",
            "saved!\n",
            "Epoch: 90, val nll=98.79369509088157, val rec=0.8034436289234795\n",
            "Epoch: 91, val nll=97.64236664156192, val rec=0.8053753244041076\n",
            "saved!\n",
            "Epoch: 92, val nll=98.10180438840521, val rec=0.8048923992142906\n",
            "Epoch: 93, val nll=97.469960117692, val rec=0.8053134147531432\n",
            "saved!\n",
            "Epoch: 94, val nll=98.19755616135262, val rec=0.803895586091214\n",
            "Epoch: 95, val nll=97.86730236320918, val rec=0.8056353537358921\n",
            "Epoch: 96, val nll=97.90336130290014, val rec=0.8055301064494791\n",
            "Epoch: 97, val nll=97.42700015134918, val rec=0.8062606808004344\n",
            "saved!\n",
            "Epoch: 98, val nll=97.93090099602168, val rec=0.8058396687806753\n",
            "Epoch: 99, val nll=98.03890484461485, val rec=0.8048862056098741\n",
            "Epoch: 100, val nll=97.50471434645988, val rec=0.8065330991005986\n",
            "Epoch: 101, val nll=97.86255490911843, val rec=0.8055115326744164\n",
            "Epoch: 102, val nll=97.21412979632726, val rec=0.8060935133057767\n",
            "saved!\n",
            "Epoch: 103, val nll=97.41233729964253, val rec=0.8061925828236935\n",
            "Epoch: 104, val nll=97.6426576283585, val rec=0.8046261727589963\n",
            "Epoch: 105, val nll=96.99185056791974, val rec=0.8060749448093542\n",
            "saved!\n",
            "Epoch: 106, val nll=97.17544521880765, val rec=0.8059077825933365\n",
            "Epoch: 107, val nll=97.5440025188826, val rec=0.8055053496272802\n",
            "Epoch: 108, val nll=97.71205595234663, val rec=0.805963495120791\n",
            "Epoch: 109, val nll=97.51267211463619, val rec=0.806601205875073\n",
            "Epoch: 110, val nll=97.42792986767758, val rec=0.8053567453504049\n",
            "Epoch: 111, val nll=97.3701638084496, val rec=0.805876819849894\n",
            "Epoch: 112, val nll=96.87323290835448, val rec=0.8069231659723823\n",
            "saved!\n",
            "Epoch: 113, val nll=96.89417720104936, val rec=0.8068364801442052\n",
            "Epoch: 114, val nll=97.02483275015855, val rec=0.8064464291083416\n",
            "Epoch: 115, val nll=97.12421307440613, val rec=0.8065145288446293\n",
            "Epoch: 116, val nll=97.09312005412535, val rec=0.8073813220231736\n",
            "Epoch: 117, val nll=97.39412990443381, val rec=0.80629163650569\n",
            "Epoch: 118, val nll=97.09527295102052, val rec=0.806725030455642\n",
            "Epoch: 119, val nll=97.02337533873386, val rec=0.8070655608089208\n",
            "Epoch: 120, val nll=96.53424162354416, val rec=0.8080437895996544\n",
            "saved!\n",
            "Epoch: 121, val nll=96.66679556871253, val rec=0.8079199527022584\n",
            "Epoch: 122, val nll=96.85646287981434, val rec=0.8074122777284292\n",
            "Epoch: 123, val nll=96.26388155666224, val rec=0.8080066367708889\n",
            "saved!\n",
            "Epoch: 124, val nll=96.36777465369869, val rec=0.8085328995961545\n",
            "Epoch: 125, val nll=97.22663862502883, val rec=0.8063287910940022\n",
            "Epoch: 126, val nll=96.59656977917436, val rec=0.8073813202636269\n",
            "Epoch: 127, val nll=96.48533895006919, val rec=0.8077465916031841\n",
            "Epoch: 128, val nll=96.31567022457334, val rec=0.8086876834010726\n",
            "Epoch: 129, val nll=96.55777146455547, val rec=0.8075670597738006\n",
            "Epoch: 130, val nll=96.7993089739247, val rec=0.8072884390714864\n",
            "Epoch: 131, val nll=96.46716871648697, val rec=0.8083224050233285\n",
            "Epoch: 132, val nll=96.50020292500288, val rec=0.8077528028030677\n",
            "Epoch: 133, val nll=96.60571874639645, val rec=0.8078209095775422\n",
            "Epoch: 134, val nll=96.66256860261474, val rec=0.8077713660208502\n"
          ]
        }
      ],
      "source": [
        "# DO NOT REMOVE OR MODIFY\n",
        "# Training procedure\n",
        "nll_val, rec_val = training(name=results_dir + name, max_patience=max_patience, num_epochs=num_epochs, model=model, optimizer=optimizer, training_loader=training_loader, val_loader=val_loader, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT REMOVE OR MODIFY\n",
        "# Final evaluation\n",
        "test_loss, test_rec = evaluation(name=results_dir + name, test_loader=test_loader, device=device)\n",
        "\n",
        "with open(results_dir + name + '_test_loss.txt', \"w\") as f:\n",
        "    f.write('Test NLL: ' + str(test_loss)+'\\n'+'Test REC: ' + str(test_rec))\n",
        "    f.close()\n",
        "\n",
        "plot_curve(results_dir + name, nll_val, ylabel='nll')\n",
        "plot_curve(results_dir + name, rec_val, ylabel='rec')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eEZj-moLdlh",
        "outputId": "1ed71c6d-13b0-44e9-d439-c3344b56fee7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FINAL LOSS: nll=98.86395286194073, rec=0.8040441780512623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3mmU18BsptW"
      },
      "source": [
        "# **2.** Model with $\\sim 500$k weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "342RZXtHtuSw"
      },
      "outputs": [],
      "source": [
        "# DO NOT REMOVE (but you can modify if necessary)\n",
        "#-creating a dir for saving results\n",
        "name = 'arm_transformer_2'  # NOTE: if you run multiple experiments, you would overwrite results. Please modify this part if necessary.\n",
        "results_dir = results_model_dir + name + '/'\n",
        "if not(os.path.exists(results_dir)):\n",
        "  os.mkdir(results_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0anyFaIthA4"
      },
      "outputs": [],
      "source": [
        "# DO NOT REMOVE but PLEASE MODIFY WHENEVER YOU ARE ASKED FOR IT!\n",
        "# NOTE: in order to obtain required sizes of your models, you can play with\n",
        "#       various values of num_neurons, num_heads, num_blocks, num_emb\n",
        "num_tokens = 150 # do not modify!\n",
        "num_token_vals = 29  # do not modify!\n",
        "num_neurons = 50 # please modify it\n",
        "num_heads = 5 # please modify it\n",
        "num_blocks = 5 # please modify it\n",
        "num_emb = num_heads * 6  # please modify it but it must be a multiplication of num_heads\n",
        "causal=True # do not modify!\n",
        "\n",
        "lr = 1e-3 # learning rate; do not modify!\n",
        "num_epochs = 1000 # max. number of epochs; do not modify!\n",
        "max_patience = 10 # an early stopping is used, if training doesn't improve for longer than 20 epochs, it is stopped; do not modify!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJzc2HPLtnKL",
        "outputId": "f0157299-5b14-401c-de01-de100c7bb102"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------\n",
            "         Layer (type)        Output Shape         Param #     Tr. Param #\n",
            "==========================================================================\n",
            "          Embedding-1        [1, 150, 30]             870             870\n",
            "          Embedding-2        [1, 150, 30]           4,500           4,500\n",
            "            Dropout-3        [1, 150, 30]               0               0\n",
            "   TransformerBlock-4        [1, 150, 30]         110,130         110,130\n",
            "   TransformerBlock-5        [1, 150, 30]         110,130         110,130\n",
            "   TransformerBlock-6        [1, 150, 30]         110,130         110,130\n",
            "   TransformerBlock-7        [1, 150, 30]         110,130         110,130\n",
            "   TransformerBlock-8        [1, 150, 30]         110,130         110,130\n",
            "             Linear-9        [1, 150, 29]             899             899\n",
            "           LossFun-10                  []               0               0\n",
            "==========================================================================\n",
            "Total params: 556,919\n",
            "Trainable params: 556,919\n",
            "Non-trainable params: 0\n",
            "--------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# DO NOT REMOVE OR MODIFY\n",
        "model = DecoderTransformer(num_tokens=num_tokens, num_token_vals=num_token_vals, num_emb=num_emb, num_neurons=num_neurons, num_heads=num_heads, num_blocks=num_blocks, device=device)\n",
        "model = model.to(device)\n",
        "# Print the summary (like in Keras)\n",
        "print(summary(model, torch.zeros(1, num_tokens, dtype=torch.long).to(device), show_input=False, show_hierarchical=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEZhrvKZt0aO"
      },
      "outputs": [],
      "source": [
        "# DO NOT REMOVE OR MODIFY\n",
        "optimizer = torch.optim.AdamW([p for p in model.parameters() if p.requires_grad == True], lr=lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTBslJfbu16m"
      },
      "source": [
        "## Training and final evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQvfp_Kat3n_",
        "outputId": "87a9c99f-8ada-4465-f04a-c7d700cd64d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, val nll=142.6662045862402, val rec=0.7140283303067253\n",
            "saved!\n",
            "Epoch: 1, val nll=134.27733721856262, val rec=0.7241945125959897\n",
            "saved!\n",
            "Epoch: 2, val nll=128.8114979874164, val rec=0.7351717526622364\n",
            "saved!\n",
            "Epoch: 3, val nll=122.59004149489738, val rec=0.7472882042071916\n",
            "saved!\n",
            "Epoch: 4, val nll=116.89857533585102, val rec=0.7598566111603346\n",
            "saved!\n",
            "Epoch: 5, val nll=113.38544557015395, val rec=0.7684254188819125\n",
            "saved!\n",
            "Epoch: 6, val nll=108.52875318914322, val rec=0.7786844718060371\n",
            "saved!\n",
            "Epoch: 7, val nll=105.47002993650543, val rec=0.7844795652861085\n",
            "saved!\n",
            "Epoch: 8, val nll=101.99314649518566, val rec=0.7927821412737519\n",
            "saved!\n",
            "Epoch: 9, val nll=99.62399100553506, val rec=0.7980200144637555\n",
            "saved!\n",
            "Epoch: 10, val nll=98.82028614902848, val rec=0.7991963611757623\n",
            "saved!\n",
            "Epoch: 11, val nll=96.96204874524331, val rec=0.8037408146031229\n",
            "saved!\n",
            "Epoch: 12, val nll=94.83151774388837, val rec=0.8063721287294507\n",
            "saved!\n",
            "Epoch: 13, val nll=93.53866948764703, val rec=0.8089043874142354\n",
            "saved!\n",
            "Epoch: 14, val nll=93.23884137706123, val rec=0.8100559702658565\n",
            "saved!\n",
            "Epoch: 15, val nll=91.50742691997233, val rec=0.8136469464460422\n",
            "saved!\n",
            "Epoch: 16, val nll=90.84141106975035, val rec=0.8143775207969975\n",
            "saved!\n",
            "Epoch: 17, val nll=91.10861397493369, val rec=0.8141298751549527\n",
            "Epoch: 18, val nll=90.20620446011588, val rec=0.8158758276063138\n",
            "saved!\n",
            "Epoch: 19, val nll=89.94663365212753, val rec=0.8169593124811939\n",
            "saved!\n",
            "Epoch: 20, val nll=89.37704704256515, val rec=0.8174793834615898\n",
            "saved!\n",
            "Epoch: 21, val nll=88.5934581123155, val rec=0.819671122350376\n",
            "saved!\n",
            "Epoch: 22, val nll=88.75886023264529, val rec=0.8187857624349559\n",
            "Epoch: 23, val nll=87.92648439301776, val rec=0.821441843940763\n",
            "saved!\n",
            "Epoch: 24, val nll=88.37418739910055, val rec=0.8202531100199232\n",
            "Epoch: 25, val nll=87.60884933190152, val rec=0.8223148272046303\n",
            "saved!\n",
            "Epoch: 26, val nll=88.31290720133764, val rec=0.8205750560408589\n",
            "Epoch: 27, val nll=87.7827711492447, val rec=0.8219495294718725\n",
            "Epoch: 28, val nll=87.71563698180927, val rec=0.8229091880066368\n",
            "Epoch: 29, val nll=87.08712982515567, val rec=0.8234973710401472\n",
            "saved!\n",
            "Epoch: 30, val nll=87.40173474976937, val rec=0.823571666140398\n",
            "Epoch: 31, val nll=87.0401525743773, val rec=0.8242898532825202\n",
            "saved!\n",
            "Epoch: 32, val nll=86.9965480227312, val rec=0.8242155599418162\n",
            "saved!\n",
            "Epoch: 33, val nll=87.38921195730512, val rec=0.8234725983820278\n",
            "Epoch: 34, val nll=87.9269816831469, val rec=0.8240855452759239\n",
            "Epoch: 35, val nll=87.72520215924816, val rec=0.8241412630820186\n",
            "Epoch: 36, val nll=88.19760525974401, val rec=0.8227791803789315\n",
            "Epoch: 37, val nll=87.34945937716213, val rec=0.8245560797378146\n",
            "Epoch: 38, val nll=87.15031742785689, val rec=0.8255714683955006\n",
            "Epoch: 39, val nll=87.41258639515107, val rec=0.8252866646460502\n",
            "Epoch: 40, val nll=87.43739662311174, val rec=0.8248161266650661\n",
            "Epoch: 41, val nll=87.14934874812616, val rec=0.8261658379952406\n",
            "Epoch: 42, val nll=87.76674322712465, val rec=0.8246118028225494\n",
            "Epoch: 43, val nll=88.05516249315325, val rec=0.8248904059293966\n"
          ]
        }
      ],
      "source": [
        "# DO NOT REMOVE OR MODIFY\n",
        "# Training procedure\n",
        "nll_val, rec_val = training(name=results_dir + name, max_patience=max_patience, num_epochs=num_epochs, model=model, optimizer=optimizer, training_loader=training_loader, val_loader=val_loader, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JO8MiSuet61x",
        "outputId": "5cfc7e15-74b6-4cd5-d88a-f41d4f5388f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FINAL LOSS: nll=90.63749689193669, rec=0.8175536838404807\n"
          ]
        }
      ],
      "source": [
        "# DO NOT REMOVE OR MODIFY\n",
        "# Final evaluation\n",
        "test_loss, test_rec = evaluation(name=results_dir + name, test_loader=test_loader, device=device)\n",
        "\n",
        "with open(results_dir + name + '_test_loss.txt', \"w\") as f:\n",
        "    f.write('Test NLL: ' + str(test_loss)+'\\n'+'Test REC: ' + str(test_rec))\n",
        "    f.close()\n",
        "\n",
        "plot_curve(results_dir + name, nll_val, ylabel='nll')\n",
        "plot_curve(results_dir + name, rec_val, ylabel='rec')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUjD-vWPstjl"
      },
      "source": [
        "# **3.** Model with $\\sim$5M weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOYzrcQmuCNm"
      },
      "outputs": [],
      "source": [
        "# DO NOT REMOVE (but you can modify if necessary)\n",
        "#-creating a dir for saving results\n",
        "name = 'arm_transformer_3'  # NOTE: if you run multiple experiments, you would overwrite results. Please modify this part if necessary.\n",
        "results_dir = results_model_dir + name + '/'\n",
        "if not(os.path.exists(results_dir)):\n",
        "  os.mkdir(results_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJA2NLP9uRIQ"
      },
      "outputs": [],
      "source": [
        "# DO NOT REMOVE but PLEASE MODIFY WHENEVER YOU ARE ASKED FOR IT!\n",
        "# NOTE: in order to obtain required sizes of your models, you can play with\n",
        "#       various values of num_neurons, num_heads, num_blocks, num_emb\n",
        "num_tokens = 150 # do not modify!\n",
        "num_token_vals = 29  # do not modify!\n",
        "num_neurons = 170 # please modify it\n",
        "num_heads = 6 # please modify it\n",
        "num_blocks = 6 # please modify it\n",
        "num_emb = num_heads * 8  # please modify it but it must be a multiplication of num_heads\n",
        "causal=True # do not modify!\n",
        "\n",
        "lr = 1e-3 # learning rate; do not modify!\n",
        "num_epochs = 1000 # max. number of epochs; do not modify!\n",
        "max_patience = 10 # an early stopping is used, if training doesn't improve for longer than 20 epochs, it is stopped; do not modify!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozIFtuybud0p",
        "outputId": "f99244f8-e867-4cb9-c915-e572f82075e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------\n",
            "         Layer (type)        Output Shape         Param #     Tr. Param #\n",
            "==========================================================================\n",
            "          Embedding-1        [1, 150, 48]           1,392           1,392\n",
            "          Embedding-2        [1, 150, 48]           7,200           7,200\n",
            "            Dropout-3        [1, 150, 48]               0               0\n",
            "   TransformerBlock-4        [1, 150, 48]         847,968         847,968\n",
            "   TransformerBlock-5        [1, 150, 48]         847,968         847,968\n",
            "   TransformerBlock-6        [1, 150, 48]         847,968         847,968\n",
            "   TransformerBlock-7        [1, 150, 48]         847,968         847,968\n",
            "   TransformerBlock-8        [1, 150, 48]         847,968         847,968\n",
            "   TransformerBlock-9        [1, 150, 48]         847,968         847,968\n",
            "            Linear-10        [1, 150, 29]           1,421           1,421\n",
            "           LossFun-11                  []               0               0\n",
            "==========================================================================\n",
            "Total params: 5,097,821\n",
            "Trainable params: 5,097,821\n",
            "Non-trainable params: 0\n",
            "--------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# DO NOT REMOVE OR MODIFY\n",
        "model = DecoderTransformer(num_tokens=num_tokens, num_token_vals=num_token_vals, num_emb=num_emb, num_neurons=num_neurons, num_heads=num_heads, num_blocks=num_blocks, device=device)\n",
        "model = model.to(device)\n",
        "# Print the summary (like in Keras)\n",
        "print(summary(model, torch.zeros(1, num_tokens, dtype=torch.long).to(device), show_input=False, show_hierarchical=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZuGlFjBugvU"
      },
      "outputs": [],
      "source": [
        "# DO NOT REMOVE OR MODIFY\n",
        "optimizer = torch.optim.AdamW([p for p in model.parameters() if p.requires_grad == True], lr=lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkkXjKMFu4Lh"
      },
      "source": [
        "## Training and final evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfT2mFMxulBE",
        "outputId": "a581edef-a880-4d4a-ecf7-a0abd928f214"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, val nll=156.06555896491582, val rec=0.6951633326681778\n",
            "saved!\n",
            "Epoch: 1, val nll=146.16275170808348, val rec=0.7100844576789884\n",
            "saved!\n",
            "Epoch: 2, val nll=140.99412666123732, val rec=0.7150313299960316\n",
            "saved!\n",
            "Epoch: 3, val nll=137.11826023228494, val rec=0.7219284786069525\n",
            "saved!\n",
            "Epoch: 4, val nll=134.49906217568034, val rec=0.7260085735813718\n",
            "saved!\n",
            "Epoch: 5, val nll=131.0279286514789, val rec=0.7324909002578567\n",
            "saved!\n",
            "Epoch: 6, val nll=127.3363843404059, val rec=0.738880370375855\n",
            "saved!\n",
            "Epoch: 7, val nll=122.00376413493139, val rec=0.7497337770637991\n",
            "saved!\n",
            "Epoch: 8, val nll=116.59743418112892, val rec=0.7616273450675486\n",
            "saved!\n",
            "Epoch: 9, val nll=110.69199272803274, val rec=0.7749572891150893\n",
            "saved!\n",
            "Epoch: 10, val nll=103.61478911114794, val rec=0.7881324581554455\n",
            "saved!\n",
            "Epoch: 11, val nll=100.03460152826626, val rec=0.7962431080666855\n",
            "saved!\n",
            "Epoch: 12, val nll=96.06888346654462, val rec=0.8037903423238945\n",
            "saved!\n",
            "Epoch: 13, val nll=93.9127611674066, val rec=0.8083100160549488\n",
            "saved!\n",
            "Epoch: 14, val nll=92.59831457384398, val rec=0.8104955595797718\n",
            "saved!\n",
            "Epoch: 15, val nll=90.0285167060655, val rec=0.8165444923063045\n",
            "saved!\n",
            "Epoch: 16, val nll=88.89553236169569, val rec=0.8169035893964591\n",
            "saved!\n",
            "Epoch: 17, val nll=87.94544538096748, val rec=0.8193925139648888\n",
            "saved!\n",
            "Epoch: 18, val nll=87.28671951575473, val rec=0.8210208301614571\n",
            "saved!\n",
            "Epoch: 19, val nll=86.86384025095134, val rec=0.8231816080663477\n",
            "saved!\n",
            "Epoch: 20, val nll=86.17825756565671, val rec=0.8237450237203788\n",
            "saved!\n",
            "Epoch: 21, val nll=86.42213738360527, val rec=0.8250142428267926\n",
            "Epoch: 22, val nll=85.52791288594038, val rec=0.8253733381574004\n",
            "saved!\n",
            "Epoch: 23, val nll=85.91089520331238, val rec=0.8260296244462918\n",
            "Epoch: 24, val nll=85.23034059869407, val rec=0.8276889104244893\n",
            "saved!\n",
            "Epoch: 25, val nll=85.9247706789812, val rec=0.8264258638079316\n",
            "Epoch: 26, val nll=85.94085175348823, val rec=0.8278003389984919\n",
            "Epoch: 27, val nll=85.20743191990026, val rec=0.8284566235278366\n",
            "saved!\n",
            "Epoch: 28, val nll=85.35381246756803, val rec=0.8292986510864483\n",
            "Epoch: 29, val nll=86.45861253351303, val rec=0.8291067038954844\n",
            "Epoch: 30, val nll=86.30889532222959, val rec=0.829156249211723\n",
            "Epoch: 31, val nll=87.18358474112085, val rec=0.8283080368464283\n",
            "Epoch: 32, val nll=86.87814229704797, val rec=0.8288095375708548\n",
            "Epoch: 33, val nll=87.54024446494465, val rec=0.8285618760928897\n",
            "Epoch: 34, val nll=87.2394201975467, val rec=0.8299735023526688\n",
            "Epoch: 35, val nll=88.0368663604849, val rec=0.8286423612784636\n",
            "Epoch: 36, val nll=88.13454761012454, val rec=0.8289766997868725\n",
            "Epoch: 37, val nll=89.89101373313538, val rec=0.8286857094711924\n",
            "Epoch: 38, val nll=89.4816076975467, val rec=0.8292491233656767\n"
          ]
        }
      ],
      "source": [
        "# DO NOT REMOVE OR MODIFY\n",
        "# Training procedure\n",
        "nll_val, rec_val = training(name=results_dir + name, max_patience=max_patience, num_epochs=num_epochs, model=model, optimizer=optimizer, training_loader=training_loader, val_loader=val_loader, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9S9ogA6EurLr",
        "outputId": "19080680-bedc-49e8-d3a1-5bd049f1baa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FINAL LOSS: nll=89.12901796010148, rec=0.8210208266423638\n"
          ]
        }
      ],
      "source": [
        "# DO NOT REMOVE OR MODIFY\n",
        "# Final evaluation\n",
        "test_loss, test_rec = evaluation(name=results_dir + name, test_loader=test_loader, device=device)\n",
        "\n",
        "with open(results_dir + name + '_test_loss.txt', \"w\") as f:\n",
        "    f.write('Test NLL: ' + str(test_loss)+'\\n'+'Test REC: ' + str(test_rec))\n",
        "    f.close()\n",
        "\n",
        "plot_curve(results_dir + name, nll_val, ylabel='nll')\n",
        "plot_curve(results_dir + name, rec_val, ylabel='rec')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5u_nOHVsyS8"
      },
      "source": [
        "# **4.** Model with $>10$M weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDG5nrQuuDGb"
      },
      "outputs": [],
      "source": [
        "# DO NOT REMOVE (but you can modify if necessary)\n",
        "#-creating a dir for saving results\n",
        "name = 'arm_transformer_4'  # NOTE: if you run multiple experiments, you would overwrite results. Please modify this part if necessary.\n",
        "results_dir = results_model_dir + name + '/'\n",
        "if not(os.path.exists(results_dir)):\n",
        "  os.mkdir(results_dir)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT REMOVE but PLEASE MODIFY WHENEVER YOU ARE ASKED FOR IT!\n",
        "# NOTE: in order to obtain required sizes of your models, you can play with\n",
        "#       various values of num_neurons, num_heads, num_blocks, num_emb\n",
        "num_tokens = 150 # do not modify!\n",
        "num_token_vals = 29  # do not modify!\n",
        "num_neurons = 220 # please modify it\n",
        "num_heads = 6 # please modify it\n",
        "num_blocks = 6 # please modify it\n",
        "num_emb = num_heads * 10  # please modify it but it must be a multiplication of num_heads\n",
        "causal=True # do not modify!\n",
        "\n",
        "lr = 1e-3 # learning rate; do not modify!\n",
        "num_epochs = 1000 # max. number of epochs; do not modify!\n",
        "max_patience = 10 # an early stopping is used, if training doesn't improve for longer than 20 epochs, it is stopped; do not modify!"
      ],
      "metadata": {
        "id": "qziTbyk4SjV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT REMOVE OR MODIFY\n",
        "model = DecoderTransformer(num_tokens=num_tokens, num_token_vals=num_token_vals, num_emb=num_emb, num_neurons=num_neurons, num_heads=num_heads, num_blocks=num_blocks, device=device)\n",
        "model = model.to(device)\n",
        "# Print the summary (like in Keras)\n",
        "print(summary(model, torch.zeros(1, num_tokens, dtype=torch.long).to(device), show_input=False, show_hierarchical=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gf_H9a4XSkdH",
        "outputId": "00b4f19e-1a62-43f9-c040-b18563732eee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------\n",
            "         Layer (type)        Output Shape         Param #     Tr. Param #\n",
            "==========================================================================\n",
            "          Embedding-1        [1, 150, 60]           1,740           1,740\n",
            "          Embedding-2        [1, 150, 60]           9,000           9,000\n",
            "            Dropout-3        [1, 150, 60]               0               0\n",
            "   TransformerBlock-4        [1, 150, 60]       1,685,040       1,685,040\n",
            "   TransformerBlock-5        [1, 150, 60]       1,685,040       1,685,040\n",
            "   TransformerBlock-6        [1, 150, 60]       1,685,040       1,685,040\n",
            "   TransformerBlock-7        [1, 150, 60]       1,685,040       1,685,040\n",
            "   TransformerBlock-8        [1, 150, 60]       1,685,040       1,685,040\n",
            "   TransformerBlock-9        [1, 150, 60]       1,685,040       1,685,040\n",
            "            Linear-10        [1, 150, 29]           1,769           1,769\n",
            "           LossFun-11                  []               0               0\n",
            "==========================================================================\n",
            "Total params: 10,122,749\n",
            "Trainable params: 10,122,749\n",
            "Non-trainable params: 0\n",
            "--------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbQFj_t0uhq_"
      },
      "outputs": [],
      "source": [
        "# DO NOT REMOVE OR MODIFY\n",
        "optimizer = torch.optim.AdamW([p for p in model.parameters() if p.requires_grad == True], lr=lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVQqlWwHu6Q9"
      },
      "source": [
        "## Training and final evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "WcaM_wArum2L",
        "outputId": "6118c1fa-8467-490e-a456-e6b5ca52741e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-001236c0fff1>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# DO NOT REMOVE OR MODIFY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Training procedure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnll_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresults_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_patience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_patience\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-956e36fd50bd>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(name, max_patience, num_epochs, model, optimizer, training_loader, val_loader, device)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# DO NOT REMOVE OR MODIFY\n",
        "# Training procedure\n",
        "nll_val, rec_val = training(name=results_dir + name, max_patience=max_patience, num_epochs=num_epochs, model=model, optimizer=optimizer, training_loader=training_loader, val_loader=val_loader, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iixk8fMWusdz"
      },
      "outputs": [],
      "source": [
        "# DO NOT REMOVE OR MODIFY\n",
        "# Final evaluation\n",
        "test_loss, test_rec = evaluation(name=results_dir + name, test_loader=test_loader, device=device)\n",
        "\n",
        "with open(results_dir + name + '_test_loss.txt', \"w\") as f:\n",
        "    f.write('Test NLL: ' + str(test_loss)+'\\n'+'Test REC: ' + str(test_rec))\n",
        "    f.close()\n",
        "\n",
        "plot_curve(results_dir + name, nll_val, ylabel='nll')\n",
        "plot_curve(results_dir + name, rec_val, ylabel='rec')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final sampled texts"
      ],
      "metadata": {
        "id": "hEgp3BXhsdnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT REMOVE\n",
        "# Sample texts: load best model\n",
        "names = ['arm_transformer_1', 'arm_transformer_2', 'arm_transformer_3','arm_transformer_4']\n",
        "\n",
        "# sample\n",
        "temperature = 1.0 # you can modify it\n",
        "num_samples = 64 # you can modify it\n",
        "\n",
        "for name in names:\n",
        "    results_dir = results_model_dir + name + '/'\n",
        "    model_best = torch.load(results_dir + name + '.model')\n",
        "    model_best = model_best.eval()\n",
        "\n",
        "    sampled_tokens = model_best.sample(batch_size=num_samples, temperature=temperature)  # do not modify\n",
        "    sampled_texts = tokenizer.decode(sampled_tokens)  # do not modify\n",
        "\n",
        "    save_texts(sampled_texts, name='FINAL_' + str(temperature))"
      ],
      "metadata": {
        "id": "r1gv0Eyisj0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5.** Model with $>10$M weights and 1000 test data"
      ],
      "metadata": {
        "id": "wOLU3JR9q0n5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PLEASE MODIFY ACCORDING TO THE REPORT REQUIREMENTS\n",
        "num_training_data = 1000  # None to take all training data\n",
        "\n",
        "# DO NOT REMOVE OR MODIFY THE REST OF THIS CELL\n",
        "#-dataset\n",
        "train_dataset = Headers(dataprocessor, tokenizer, num_training_data=num_training_data, mode=\"train\")\n",
        "validation_dataset = Headers(dataprocessor, tokenizer, mode=\"val\")\n",
        "test_dataset = Headers(dataprocessor, tokenizer, mode=\"test\")\n",
        "\n",
        "#-dataloaders\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "training_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "id": "-cb0_osBrLWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT REMOVE (but you can modify if necessary)\n",
        "#-creating a dir for saving results\n",
        "name = 'arm_transformer_1000'  # NOTE: if you run multiple experiments, you would overwrite results. Please modify this part if necessary.\n",
        "results_dir = results_model_dir + name + '/'\n",
        "if not(os.path.exists(results_dir)):\n",
        "  os.mkdir(results_dir)"
      ],
      "metadata": {
        "id": "HUQcykPfqyJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT REMOVE but PLEASE MODIFY WHENEVER YOU ARE ASKED FOR IT!\n",
        "# NOTE: in order to obtain required sizes of your models, you can play with\n",
        "#       various values of num_neurons, num_heads, num_blocks, num_emb\n",
        "num_tokens = 150 # do not modify!\n",
        "num_token_vals = 29  # do not modify!\n",
        "num_neurons = 50 # please modify it\n",
        "num_heads = 5 # please modify it\n",
        "num_blocks = 5 # please modify it\n",
        "num_emb = num_heads * 6  # please modify it but it must be a multiplication of num_heads\n",
        "causal=True # do not modify!\n",
        "\n",
        "lr = 1e-3 # learning rate; do not modify!\n",
        "num_epochs = 1000 # max. number of epochs; do not modify!\n",
        "max_patience = 10 # an early stopping is used, if training doesn't improve for longer than 20 epochs, it is stopped; do not modify!"
      ],
      "metadata": {
        "id": "z456WmVurer1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT REMOVE OR MODIFY\n",
        "model = DecoderTransformer(num_tokens=num_tokens, num_token_vals=num_token_vals, num_emb=num_emb, num_neurons=num_neurons, num_heads=num_heads, num_blocks=num_blocks, device=device)\n",
        "model = model.to(device)\n",
        "# Print the summary (like in Keras)\n",
        "print(summary(model, torch.zeros(1, num_tokens, dtype=torch.long).to(device), show_input=False, show_hierarchical=False))"
      ],
      "metadata": {
        "id": "qpIi-fx5rmvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT REMOVE OR MODIFY\n",
        "optimizer = torch.optim.AdamW([p for p in model.parameters() if p.requires_grad == True], lr=lr)"
      ],
      "metadata": {
        "id": "v9gQUj8grtM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT REMOVE OR MODIFY\n",
        "# Training procedure\n",
        "nll_val, rec_val = training(name=results_dir + name, max_patience=max_patience, num_epochs=num_epochs, model=model, optimizer=optimizer, training_loader=training_loader, val_loader=val_loader, device=device)"
      ],
      "metadata": {
        "id": "p3vQ6-_grtsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT REMOVE OR MODIFY\n",
        "# Final evaluation\n",
        "test_loss, test_rec = evaluation(name=results_dir + name, test_loader=test_loader, device=device)\n",
        "\n",
        "with open(results_dir + name + '_test_loss.txt', \"w\") as f:\n",
        "    f.write('Test NLL: ' + str(test_loss)+'\\n'+'Test REC: ' + str(test_rec))\n",
        "    f.close()\n",
        "\n",
        "plot_curve(results_dir + name, nll_val, ylabel='nll')\n",
        "plot_curve(results_dir + name, rec_val, ylabel='rec')"
      ],
      "metadata": {
        "id": "629a_PXvQsiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final sampled texts"
      ],
      "metadata": {
        "id": "rIXLOIWPtXBJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcQ0GPZy3TOE"
      },
      "outputs": [],
      "source": [
        "# DO NOT REMOVE\n",
        "# Sample texts: load best model\n",
        "model_best = torch.load(results_dir + name + '.model')\n",
        "model_best = model_best.eval()\n",
        "\n",
        "# sample\n",
        "temperature = 1.0 # you can modify it\n",
        "num_samples = 64 # you can modify it\n",
        "\n",
        "sampled_tokens = model_best.sample(batch_size=num_samples, temperature=temperature)  # do not modify\n",
        "sampled_texts = tokenizer.decode(sampled_tokens)  # do not modify\n",
        "\n",
        "save_texts(sampled_texts, name='FINAL_' + str(temperature))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FB75fePzuUSG"
      },
      "source": [
        "# Best Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT REMOVE\n",
        "# Sample texts: load best model\n",
        "name = 'arm_transformer_2'\n",
        "results_dir = results_model_dir + name + '/'\n",
        "# sample\n",
        "temperatures = [0.01, 0.1, 0.5, 0.8, 1.0] # you can modify it\n",
        "num_samples = 64 # you can modify it\n",
        "\n",
        "for temperature in temperatures:\n",
        "  model_best = torch.load(results_dir + name + '.model')\n",
        "  model_best = model_best.eval()\n",
        "\n",
        "  sampled_tokens = model_best.sample(batch_size=num_samples, temperature=temperature)  # do not modify\n",
        "  sampled_texts = tokenizer.decode(sampled_tokens)  # do not modify\n",
        "\n",
        "  save_texts(sampled_texts, name='FINAL_' + str(temperature))"
      ],
      "metadata": {
        "id": "8eMxUhNrMJc2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "35a467530d66453689e2a0113109f774": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce9b81ec6f944b7387b9c06330bc75fe",
              "IPY_MODEL_66f8d6eff444476ab8f67392746021fd",
              "IPY_MODEL_3fb34f18e4bd44c8bd1a5f3df45cb02b"
            ],
            "layout": "IPY_MODEL_484775bf86f549f9a0f72fe6e9c0a59f"
          }
        },
        "ce9b81ec6f944b7387b9c06330bc75fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ce89fbe5fa846bd9e6585d47ff47799",
            "placeholder": "​",
            "style": "IPY_MODEL_30481408fb7947208009c49077d006ff",
            "value": "Downloading data: 100%"
          }
        },
        "66f8d6eff444476ab8f67392746021fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f49197a76ac64b5cbec02632b21818f9",
            "max": 1128431,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ec0a29b00504684a9a77c8675edcd0b",
            "value": 1128431
          }
        },
        "3fb34f18e4bd44c8bd1a5f3df45cb02b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94b884fdc3ea4535848bc71b01890545",
            "placeholder": "​",
            "style": "IPY_MODEL_46ec987408f3427aad71a1f1c9fb7d48",
            "value": " 1.13M/1.13M [00:00&lt;00:00, 2.63MB/s]"
          }
        },
        "484775bf86f549f9a0f72fe6e9c0a59f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ce89fbe5fa846bd9e6585d47ff47799": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30481408fb7947208009c49077d006ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f49197a76ac64b5cbec02632b21818f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ec0a29b00504684a9a77c8675edcd0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "94b884fdc3ea4535848bc71b01890545": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46ec987408f3427aad71a1f1c9fb7d48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "937c88cbc55647c0a6aaded271fc111c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4e496431a95144efa1c8b48ee5df1f06",
              "IPY_MODEL_a7c2b4812d88444d869d43c1f28e3fa3",
              "IPY_MODEL_d68b00809f824d45bbd56ff8a6f575c7"
            ],
            "layout": "IPY_MODEL_70d458b2f7e94a6ba7f3f148c6d5b599"
          }
        },
        "4e496431a95144efa1c8b48ee5df1f06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6413b232982d41a2bd438256a63ce097",
            "placeholder": "​",
            "style": "IPY_MODEL_ee55f368c2ed4cd4af1824cc0566d7f6",
            "value": "Downloading data: 100%"
          }
        },
        "a7c2b4812d88444d869d43c1f28e3fa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f765e7fcbc2042e0afba9201f167c000",
            "max": 147644,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a853f46f412643bca98045b23f72319e",
            "value": 147644
          }
        },
        "d68b00809f824d45bbd56ff8a6f575c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa7dca7dd761463eb51328506a239d56",
            "placeholder": "​",
            "style": "IPY_MODEL_33fe0e4fe4564a9d86ee4fae8585011a",
            "value": " 148k/148k [00:00&lt;00:00, 1.21MB/s]"
          }
        },
        "70d458b2f7e94a6ba7f3f148c6d5b599": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6413b232982d41a2bd438256a63ce097": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee55f368c2ed4cd4af1824cc0566d7f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f765e7fcbc2042e0afba9201f167c000": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a853f46f412643bca98045b23f72319e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aa7dca7dd761463eb51328506a239d56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33fe0e4fe4564a9d86ee4fae8585011a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "820119839ddc4b73a69aa5ee131ba22f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2684bf5601154780a411081e6b79ad70",
              "IPY_MODEL_e1482300b86c46dea53aea5cd9d6596e",
              "IPY_MODEL_fcc4cf07f4724b4f885a4e93717c19e1"
            ],
            "layout": "IPY_MODEL_fc4beaf3552b416e95b68222a48edd6e"
          }
        },
        "2684bf5601154780a411081e6b79ad70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3d63e3eab564014a058ef067a1d363a",
            "placeholder": "​",
            "style": "IPY_MODEL_a601020ef32e42ce907b9387bdf260c6",
            "value": "Downloading data: 100%"
          }
        },
        "e1482300b86c46dea53aea5cd9d6596e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c28477916114428aa951e747153ee13d",
            "max": 145412,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e0ee5d6a512c492b856874eee4ee61fc",
            "value": 145412
          }
        },
        "fcc4cf07f4724b4f885a4e93717c19e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5561ac636c14b6d8852dfb0fc3b3d58",
            "placeholder": "​",
            "style": "IPY_MODEL_bcd3a12afd2942359c41cf3105de327b",
            "value": " 145k/145k [00:00&lt;00:00, 1.46MB/s]"
          }
        },
        "fc4beaf3552b416e95b68222a48edd6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3d63e3eab564014a058ef067a1d363a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a601020ef32e42ce907b9387bdf260c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c28477916114428aa951e747153ee13d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0ee5d6a512c492b856874eee4ee61fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f5561ac636c14b6d8852dfb0fc3b3d58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcd3a12afd2942359c41cf3105de327b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f05bbf93ff74af190ddc641c5949fc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_86b315fb87da4d65a62634fa1e249309",
              "IPY_MODEL_f2a8e8fefcf344369ea9f32e5fb9b224",
              "IPY_MODEL_4006b1b90e7f4c1b8235f32a8462a4ac"
            ],
            "layout": "IPY_MODEL_8947aa44eb0b425c9f396f108aecfbf9"
          }
        },
        "86b315fb87da4d65a62634fa1e249309": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a60afda4868140fdb60b3461c7580c95",
            "placeholder": "​",
            "style": "IPY_MODEL_1f481007ad43439ba66a400b66c70ee8",
            "value": "Generating train split: 100%"
          }
        },
        "f2a8e8fefcf344369ea9f32e5fb9b224": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db860757ea2a4c2f84c8ff6b419dacba",
            "max": 4332,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f1cf756c2a1d4d2a9cfffe2f340a108a",
            "value": 4332
          }
        },
        "4006b1b90e7f4c1b8235f32a8462a4ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3842daadc5c848afbc4b70da45752679",
            "placeholder": "​",
            "style": "IPY_MODEL_6233591379524fe6be018304e7dae044",
            "value": " 4332/4332 [00:00&lt;00:00, 9895.31 examples/s]"
          }
        },
        "8947aa44eb0b425c9f396f108aecfbf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a60afda4868140fdb60b3461c7580c95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f481007ad43439ba66a400b66c70ee8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db860757ea2a4c2f84c8ff6b419dacba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1cf756c2a1d4d2a9cfffe2f340a108a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3842daadc5c848afbc4b70da45752679": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6233591379524fe6be018304e7dae044": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e012b07b3128486bb9e6771b9c235ec1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fecbd7889b914931b9751e15b7d2b720",
              "IPY_MODEL_5a8e1e738a2045f69004eb9e95e57ec7",
              "IPY_MODEL_a15cd8e9bf9345a5805c245e4c628ec9"
            ],
            "layout": "IPY_MODEL_73c4baf1a6604bcca121f7fff447df6f"
          }
        },
        "fecbd7889b914931b9751e15b7d2b720": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29fbd1094b714b87ae5bbbf4aad98baa",
            "placeholder": "​",
            "style": "IPY_MODEL_08fc3a4bb2944b319042e09de4de22c5",
            "value": "Generating test split: 100%"
          }
        },
        "5a8e1e738a2045f69004eb9e95e57ec7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd0be328924945858a55c1e8c3758887",
            "max": 542,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e57868a2b05a4873adf4fe126c5400f4",
            "value": 542
          }
        },
        "a15cd8e9bf9345a5805c245e4c628ec9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e9e56cee3ea47ce9a27c5c6e1a4a23a",
            "placeholder": "​",
            "style": "IPY_MODEL_517ee8860c09433f9da28af92f2acfc6",
            "value": " 542/542 [00:00&lt;00:00, 14031.24 examples/s]"
          }
        },
        "73c4baf1a6604bcca121f7fff447df6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29fbd1094b714b87ae5bbbf4aad98baa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08fc3a4bb2944b319042e09de4de22c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd0be328924945858a55c1e8c3758887": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e57868a2b05a4873adf4fe126c5400f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e9e56cee3ea47ce9a27c5c6e1a4a23a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "517ee8860c09433f9da28af92f2acfc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1df2ccf9bf3e4399b8e081497a1520c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ecf4cf0984045e8bae39d7279dd1670",
              "IPY_MODEL_ce661f686b904c0381b5f6432ea9880b",
              "IPY_MODEL_4201f46209c24701aabe4be7ff490044"
            ],
            "layout": "IPY_MODEL_15746ca77fbd40e5a12b09192d96bd91"
          }
        },
        "1ecf4cf0984045e8bae39d7279dd1670": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87e8fccc5a6b48878169f15c6fdbc9f9",
            "placeholder": "​",
            "style": "IPY_MODEL_45f92e3492f24b278b3d233f8c09a4b3",
            "value": "Generating validation split: 100%"
          }
        },
        "ce661f686b904c0381b5f6432ea9880b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aaa5cc1343c6464c89b7eee18c4720af",
            "max": 542,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a3ea1ee14cbf4fd5abac431dcad78d6f",
            "value": 542
          }
        },
        "4201f46209c24701aabe4be7ff490044": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9add18beb9df4e269c623cc5c20df508",
            "placeholder": "​",
            "style": "IPY_MODEL_68ccc11c2c4b47248e26d85c37150de6",
            "value": " 542/542 [00:00&lt;00:00, 12926.47 examples/s]"
          }
        },
        "15746ca77fbd40e5a12b09192d96bd91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87e8fccc5a6b48878169f15c6fdbc9f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45f92e3492f24b278b3d233f8c09a4b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aaa5cc1343c6464c89b7eee18c4720af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3ea1ee14cbf4fd5abac431dcad78d6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9add18beb9df4e269c623cc5c20df508": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68ccc11c2c4b47248e26d85c37150de6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}